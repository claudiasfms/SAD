{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3ºTPC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudiasfms/SAD/blob/master/3%C2%BATPC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "HGjtpH111y4a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Cláudia Santos nº20160291\n",
        "#entrega dia 19 Novembro\n",
        "\"\"\"Crie um ficheiro em python para trabalhar o dataset datasets.california_housing\n",
        "Nesse ficheiro, crie um script (função) por alínea que lhe permita gerar novos datasets a partir do dataset principal, onde tenha usado cada um dos seguintes métodos de pre-processamento:\n",
        "\n",
        "1) Aggregation (houses_below.aggregate([\"sum\", \"mean\", \"max\"]))\n",
        "2) Sampling  \n",
        "4) Dimensionality Reduction \n",
        "5) Feature Subset Selection \n",
        "6) Feature Creation \n",
        "7) Discretization and Binarization \n",
        "8) Attribute Transformation \"\"\"\n",
        "\n",
        "#importar módulos\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from functools import reduce \n",
        "\n",
        "#importação do dataset\n",
        "data = datasets.california_housing.fetch_california_housing()\n",
        "\n",
        "print(data.DESCR)\n",
        "print(data.feature_names)  #imprime os nomes principais (classes)\n",
        "data.keys()  #vai buscar as chaves do dicionário\n",
        "\n",
        "#mostra os dados em colunas (1ºs 5 (head))\n",
        "dframe = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "dframe.head()\n",
        "\n",
        "#mostra os dados mas desta vez com as classes\n",
        "alldata = np.column_stack((data.data,data.target))\n",
        "allnames = np.append(data.feature_names,\"Classe\")\n",
        "dframe = pd.DataFrame(alldata, columns=allnames)\n",
        "dframe.head()\n",
        "dframe\n",
        "\n",
        "stat = dframe.groupby(\"Classe\").agg([\"mean\",\"count\", \"std\"])\n",
        "stat\n",
        "\n",
        "#função p gerar novos datasets a partir do dataset principal\n",
        "#1) Aggregation\n",
        "houses_below = dframe.loc[dframe[\"MedInc\"]<10,:]\n",
        "houses_below[:10]\n",
        "houses_below.count()\n",
        "houses_below.aggregate([\"sum\", \"mean\", \"max\"])\n",
        "\n",
        "\n",
        "#2) Sampling\n",
        "random_subset = dframe.sample(n=3)\n",
        "print(random_subset.head())\n",
        "\n",
        "\n",
        "#4) Dimensionality Reduction e 5) Feature Subset Selection \n",
        "df=dframe.drop('Latitude', 1) \n",
        "df.corr()\n",
        "df=dframe.drop(['AveBedrms', 'Longitude'], axis=1)  #remover colunas\n",
        "model = RandomForestRegressor(random_state=1, max_depth=10)  #fazer um modelo com random forest\n",
        "df=pd.get_dummies(df)  #converte variaveis categóricas em variáveis indicadoras\n",
        "model.fit(df, dframe.Latitude)\n",
        "#fazer o gráfico\n",
        "features = df.columns\n",
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)[-5:]  #top 5 features\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#6) Feature Creation\n",
        "# É criado um vetor com o tamanho de \"data\", colocando número de ocorrências de cada letra na posição apropriada do vetor\n",
        "dictionary = list(enumerate(set(list(reduce(lambda x, y: x + y, data)))))\n",
        "def vectorize(text): \n",
        "    vector = np.zeros(len(dictionary)) \n",
        "    for i, word in dictionary: \n",
        "        num = 0 \n",
        "        for w in text: \n",
        "            if w == word: \n",
        "                num += 1 \n",
        "        if num: \n",
        "            vector[i] = num \n",
        "    return vector\n",
        "for t in data: \n",
        "    print(vectorize(t))\n",
        "\n",
        "\n",
        "#7) Discretization and Binarization \n",
        "plt.figure()\n",
        "plt.grid()\n",
        "plt.axis('equal')\n",
        "data1 = np.random.randn(200,2)\n",
        "data2 = np.random.randn(200,2)+1.75\n",
        "plt.plot(data1[:,0],data1[:,1],  '.', color=\"b\")\n",
        "plt.plot(data2[:,0],data2[:,1],  '.', color=\"r\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#8) Attribute Transformation\n",
        "#1a opção: merging\n",
        "df.groupby('HouseAge')[\"Population\"].sum()   #ordena os dados pela HouseAge\n",
        "#vai combinar estas duas colunas\n",
        "total = df.groupby('HouseAge')[\"Population\"].sum().rename(\"Total\").reset_index()\n",
        "df_1 = df.merge(total)\n",
        "df_1[\"Percentagem Total\"] = df_1[\"Population\"] / df_1[\"Total\"]\n",
        "df_1\n",
        "\n",
        "#2a opção: transform\n",
        "df.groupby('HouseAge')[\"Population\"].transform('sum')\n",
        "df[\"Total\"] = df.groupby('HouseAge')[\"Population\"].transform('sum')\n",
        "df[\"Percentagem Total\"] = df[\"Population\"] / df[\"Total\"]\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}