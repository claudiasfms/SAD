{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 169.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"FullyConnected_1/Softmax:0\", shape=(?, 2), dtype=float32)\n",
      "---------------------------------\n",
      "Run id: modeloEstudo\n",
      "Log directory: log/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 100\n",
      "Validation samples: 50\n",
      "--\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (64,) for Tensor 'targets/Y:0', which has shape '(?, 2)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-eb4e9d9d83bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;31m#A informação vai ser inserida no modelo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m model.fit({'input': X}, {'targets': Y}, n_epoch=10, validation_set=({'input': TesteX}, {'targets': TesteY}), #n_epoch=Training step\n\u001b[1;32m--> 138\u001b[1;33m    snapshot_step=50, show_metric=True, run_id='modeloEstudo')\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tflearn\\models\\dnn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[0;32m    214\u001b[0m                          \u001b[0mexcl_trainops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexcl_trainops\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                          \u001b[0mrun_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                          callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tflearn\\helpers\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, feed_dicts, n_epoch, val_feed_dicts, show_metric, snapshot_step, snapshot_epoch, shuffle_all, dprep_dict, daug_dict, excl_trainops, run_id, callbacks)\u001b[0m\n\u001b[0;32m    337\u001b[0m                                                        \u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0msnapshot_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m                                                        \u001b[0msnapshot_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m                                                        show_metric)\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                             \u001b[1;31m# Update training state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tflearn\\helpers\\trainer.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, training_step, snapshot_epoch, snapshot_step, show_metric)\u001b[0m\n\u001b[0;32m    816\u001b[0m         \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m         _, train_summ_str = self.session.run([self.train, self.summ_op],\n\u001b[1;32m--> 818\u001b[1;33m                                              feed_batch)\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[1;31m# Retrieve loss value from summary string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1128\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1129\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (64,) for Tensor 'targets/Y:0', which has shape '(?, 2)'"
     ]
    }
   ],
   "source": [
    "'''TPC 6 parte 2 trabalho final\n",
    "\n",
    "OpenCV is in BGR mode. But Matplotlib displays in RGB. A diferença entre opencv e matplotlib é a forma como mostra as cores.\n",
    "Para a parte da precisão (dados treino e teste) usamos o opencv, e para mostrar os animais usamos o matplotlib.\n",
    "\n",
    "coisas a instalar linha comandos python:\n",
    "sudo pip3 install pandas\n",
    "pip3 install matplotlib\n",
    "pip3 install opencv-python\n",
    "pip3 install sklearn\n",
    "pip3 install tqdm \n",
    "pip3 install tflearn\n",
    "pip3 install tensorflow\n",
    "\n",
    "Treino tem ficheiros 100 (50 Esquilo + 50 Elefante). Teste tem ficheiros 50 (25 Esquilo + 25 Elefante)\n",
    "Para efectuarmos o estudo e identificação do tipo de animal renomeamos os ficheiros:\n",
    "ex:\n",
    "Esquilo.0.jpeg\n",
    "Esquilo.1.jpeg\n",
    "...\n",
    "Elefante.0.jpeg\n",
    "Elefante.1.jpeg\n",
    "\n",
    "#acc is the accuracy (precisão) of a batch of training data and val_acc is the accuracy of a batch of testing\n",
    "#acc é a precisão dos dados de treino e val_acc é a precisão dos dados de teste\n",
    "'''\n",
    "\n",
    "import numpy as np #arrays\n",
    "import os #diretorias\n",
    "import cv2 #tratamento do tamanho da imagem\n",
    "import matplotlib.pyplot as plt #Usado para poder mostrar os animais \n",
    "import pandas as pd\n",
    "from random import shuffle #escolhe aleatoriamente os dados\n",
    "from tqdm import tqdm #loops - barra de progresso \n",
    "from sklearn import datasets, tree, model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "%matplotlib inline\n",
    "# código tflearn- https://pythonprogramming.net/tflearn-machine-learning-tutorial/\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import tensorflow as tf  #faz o reset dos dados \n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "image_Size=50 #dimensão imagem (pixeis 50x50)\n",
    " \n",
    "learning_Rate=1e-3 #0.001 permite determinar valores com mais precisão no universo em estudo (MAX,MIN)\n",
    "\n",
    "path_Directory_Treino=\"C:/animals10/Treino\" #amostra de treino\n",
    "path_Directory_Teste=\"C:/animals10/Teste\"  #amostra do teste\n",
    "\n",
    "#padronizar o modelo quanto à formatação e para 6 layers\n",
    "model_Identification=\"animals_Esquilo_Elefante-{}-{}.model\".format(learning_Rate,\"6conv-basic-video\")\n",
    "#\"2conv-basic-video\" Layers p/ 1 - linear | >=2 - não linear\n",
    "\n",
    "#com estas funções vamos determinar a probabilidade da imagem ser Esquilo ou Elefante\n",
    "#Funcao para determinar a imagem(label Esquilo ou Elefante) na path_Directory\n",
    "def label_image(image):\n",
    "    animal_label=image.split(\".\")[-3] # exemplo: Esquilo.0.jpeg\n",
    "    if animal_label==\"Esquilo\": return 1\n",
    "    elif animal_label==\"Elefante\": return 0\n",
    "\n",
    "#Vamos determinar a precisão Accuracy pela Funcao de treino e a função de teste utilizada com base na primeira.\n",
    "#Funcao de treino apenas precisa de ser executa 1 primeira vez, temos as imagens/features e a labels servem para determinar a precisão(accuracy)\n",
    "def create_Treino():\n",
    "\ttreino_data=[] #Iniciação lista vazia\n",
    "\tfor image in tqdm(os.listdir(path_Directory_Treino)):\n",
    "\t\tlabel=label_image(image)\n",
    "\t\tpath=os.path.join(path_Directory_Treino,image) #Junta o path com a imagem\n",
    "\t\timage=cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE),(image_Size,image_Size)) # padronizar o tamanho, e ler imagens a cinzento\n",
    "\t\ttreino_data.append([np.array(image),label]) # adicionar no array com o label e imagem num formato numpy\n",
    "\t\tshuffle(treino_data) #mistura os dados treino\n",
    "\t\tnp.save('treino_data.npy',treino_data) # guarda os dados resultante do treino\n",
    "\treturn treino_data # retorna os dados\n",
    "\n",
    "\n",
    "#Funcao de Teste ajuda a determinar a accuracy pela utilizacao dos dados de treino sem a existência de labels\n",
    "def execucao_Teste():\n",
    "\tteste_data=[]\n",
    "\tfor image in tqdm(os.listdir(path_Directory_Teste)):\n",
    "\t\tpath=os.path.join(path_Directory_Teste,image) #Junta o path com a imagem\n",
    "\t\timage_id=image.split('.')[0]\n",
    "\t\timage=cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE),(image_Size,image_Size)) # padronizar o tamanho, e ler imagens a cinzento\n",
    "\t\tteste_data.append([np.array(image),image_id]) #Associa imagem ao id\n",
    "\tnp.save('teste_data.npy',teste_data)\n",
    "\treturn teste_data\n",
    "\n",
    "#Criar os dados de treino\n",
    "treino_data=create_Treino()\n",
    "\n",
    "# código tflearn\n",
    "convnet = input_data(shape=[None, image_Size, image_Size, 1], name='input')# tamanho de imagem definido em image_Size\n",
    "\n",
    "#6 layers (aumenta-se nr layers p melhorar a precisão)\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "convnet = fully_connected(convnet, 2, activation='softmax') # 2:  Esquilo ou Elefante\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=learning_Rate, loss='categorical_crossentropy', name='targets')# Definido learning_Rate\n",
    "print(convnet)\n",
    "model = tflearn.DNN(convnet,tensorboard_dir='log') #cria registos de actividade\n",
    "\n",
    "\n",
    "\n",
    "#carrega o existente\n",
    "treino_data=np.load('treino_data.npy')\n",
    "teste_data=np.load('teste_data.npy')\n",
    "\n",
    "#Determinar a Accuracy entre os dados de treino e de teste P/ accuracy semelhante\n",
    "treino=treino_data[:100] #100 exemplos de dados\n",
    "teste= treino_data[-50:] #usa os ultimos 50\n",
    "\n",
    "#standardizar ou seja converter em numpy array as imagens e os labels \n",
    "# X: feature sets Y: label sets\n",
    "X=np.array([i[0] for i in treino]).reshape(-1,image_Size,image_Size,1) #i[0] posição com as imagens e dimensionamento das imagens\n",
    "Y=[i[1] for i in treino]\n",
    "\n",
    "#Testar a accuracy de X e Y anteriores. A diferença é que é de teste (accuracy), enquanto o de cima é de treino (fit)\n",
    "TesteX=np.array([i[0] for i in teste]).reshape(-1,image_Size,image_Size,1) #i[0] posição com as imagens e dimensionamento das imagens\n",
    "TesteY=[i[1] for i in teste]\n",
    "\n",
    "#A informação vai ser inserida no modelo\n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch=10, validation_set=({'input': TesteX}, {'targets': TesteY}), #n_epoch=Training step\n",
    "   snapshot_step=50, show_metric=True, run_id='modeloEstudo')\n",
    "\n",
    "\n",
    "#Identificar os animais\n",
    "teste_data=execucao_Teste()\n",
    "fig=plt.figure()\n",
    "for id,dataAnimal in enumerate(treino_data[:12]):#Vou mostrar 12 animais\n",
    "    #esquilo: [1, 0]\n",
    "    #elefante: [0, 1]\n",
    "    image_id=dataAnimal[1]\n",
    "    data_image=dataAnimal[0]\n",
    "    y=fig.add_subplot(3,4,id+1)#mostra a matriz com as imagens 4x3 com incremento do id\n",
    "    source_image=data_image\n",
    "    dataAnimal=data_image.reshape(image_Size,image_Size,1) #padronizar o tamanho das imagens\n",
    "    modelo=model.predict([dataAnimal])[0]# lista de 1 prediction (previsão)\n",
    "\n",
    "    if np.argmax(modelo)==1: label_animal=\"Elefante\"\n",
    "    else: label_animal=\"Esquilo\"\n",
    "    \n",
    "    y.imshow(source_image,cmap=\"gray\")# para a imagem mostrar em cinzento\n",
    "    plt.title(label_animal)\n",
    "    y.axes.get_xaxis().set_visible(False) #Não mostra o eixo do x\n",
    "    y.axes.get_yaxis().set_visible(False) #Não mostra o eixo do y\n",
    "plt.show()# Mostra a imagem e o titulo\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "#Write e Append csv\n",
    "with open('submeter_ficheiro.csv', 'w') as f:\n",
    "    f.write('id, label\\n')\n",
    " \n",
    "with open('submeter_ficheiro.csv', 'a') as f:\n",
    "    for data in tqdm(teste_data):\n",
    "        img_num = data[1]\n",
    "        img_data = data[0]\n",
    "        orig = img_data\n",
    "        data = img_data.reshape(image_Size, image_Size, 1)\n",
    "        model_out = model.predict([data])[0]\n",
    "        f.write('{},{}\\n'.format(img_num,model_out[1]))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 50, 50, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################\n",
    "TesteX.shape\n",
    "\n",
    "(50, 50, 50, 1)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.reshape(100, -1,1).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)\n",
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "score_train: 1.0\n",
      "score_test: 0.5\n",
      "--------------------------------------------\n",
      "Random Forest\n",
      "score_train: 1.0\n",
      "score_test: 0.7333333333333333\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "[features_train, features_test, classes_train, classes_test] = model_selection.train_test_split(X.reshape(100, -1,1).squeeze(), Y, test_size=0.30)\n",
    "model = tree.DecisionTreeClassifier()\n",
    "clf = model.fit(features_train, classes_train)\n",
    "score_train = model.score(features_train, classes_train)\n",
    "score_test = model.score(features_test, classes_test)\n",
    "print (\"Decision Tree\")\n",
    "print(\"score_train:\", score_train)\n",
    "print(\"score_test:\", score_test)\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "\n",
    "#Random Forest \n",
    "[features_train, features_test, classes_train, classes_test] = model_selection.train_test_split(X.reshape(100, -1,1).squeeze(), Y, test_size=0.30)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "clf = model.fit(features_train, classes_train)\n",
    "clf\n",
    "score_train = model.score(features_train, classes_train)\n",
    "score_test = model.score(features_test, classes_test)\n",
    "print (\"Random Forest\")\n",
    "#print(\"Features:\", digits.target_names)\n",
    "print(\"score_train:\", score_train)\n",
    "print(\"score_test:\", score_test)\n",
    "print(\"--------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
